{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/santhosr/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "import time\n",
    "import string\n",
    "import itertools\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import filterfalse\n",
    "from functools import reduce\n",
    "from scipy import sparse\n",
    "\n",
    "import gc\n",
    "\n",
    "from dask import distributed\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class NotTrainedError(Exception):\n",
    "    pass\n",
    "\n",
    "class NotFitToCorpusError(Exception):\n",
    "    pass\n",
    "\n",
    "class GloVeModel():\n",
    "    def __init__(self, embedding_size, context_size, max_vocab_size=100000, min_occurrences=1,\n",
    "                 scaling_factor=3/4, cooccurrence_cap=100, batch_size=512, learning_rate=0.05):\n",
    "        self.embedding_size = embedding_size\n",
    "        if isinstance(context_size, tuple):\n",
    "            self.left_context, self.right_context = context_size\n",
    "        elif isinstance(context_size, int):\n",
    "            self.left_context = self.right_context = context_size\n",
    "        else:\n",
    "            raise ValueError(\"`context_size` should be an int or a tuple of two ints\")\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.min_occurrences = min_occurrences\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.cooccurrence_cap = cooccurrence_cap\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.__words = None\n",
    "        self.__word_to_id = None\n",
    "        self.__cooccurrence_matrix = None\n",
    "        self.__embeddings = None\n",
    "\n",
    "    def fit_to_corpus(self, corpus):\n",
    "        self.__fit_to_corpus(corpus, self.max_vocab_size, self.min_occurrences,\n",
    "                             self.left_context, self.right_context)\n",
    "        self.__build_graph()\n",
    "\n",
    "    def __fit_to_corpus(self, corpus, vocab_size, min_occurrences, left_size, right_size):\n",
    "        word_counts = Counter()\n",
    "        cooccurrence_counts = defaultdict(float)\n",
    "        for region in tqdm(corpus):\n",
    "            word_counts.update(region)\n",
    "            for l_context, word, r_context in _context_windows(region, left_size, right_size):\n",
    "                for i, context_word in enumerate(l_context[::-1]):\n",
    "                    # add (1 / distance from focal word) for this pair\n",
    "                    cooccurrence_counts[(word, context_word)] += 1 / (i + 1)\n",
    "                for i, context_word in enumerate(r_context):\n",
    "                    cooccurrence_counts[(word, context_word)] += 1 / (i + 1)\n",
    "        if len(cooccurrence_counts) == 0:\n",
    "            raise ValueError(\"No coccurrences in corpus. Did you try to reuse a generator?\")\n",
    "        self.__words = [word for word, count in word_counts.most_common(vocab_size)\n",
    "                        if count >= min_occurrences]\n",
    "        self.__word_to_id = {word: i for i, word in enumerate(self.__words)}\n",
    "        self.__cooccurrence_matrix = {\n",
    "            (self.__word_to_id[words[0]], self.__word_to_id[words[1]]): count\n",
    "            for words, count in cooccurrence_counts.items()\n",
    "            if words[0] in self.__word_to_id and words[1] in self.__word_to_id}\n",
    "        \n",
    "        \n",
    "    def fit_to_cmatrix(self, cmatrix):\n",
    "        \n",
    "        wordCount = pickle.load(open('wordCount','rb'))\n",
    "        vocab = wordCount.most_common(self.vocab_size)\n",
    "\n",
    "        ## Creating the Word-ID dictionaries\n",
    "        self.__id_to_word = {i:x[0] for i,x in enumerate(vocab)}\n",
    "\n",
    "        self.__word_to_id = {value:key for key,value in id_to_word.items()}\n",
    "        \n",
    "        self.__words = set(self.__word_to_id.keys())\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __build_graph(self):\n",
    "        self.__graph = tf.Graph()\n",
    "        with self.__graph.as_default(), self.__graph.device(_device_for_node):\n",
    "            count_max = tf.constant([self.cooccurrence_cap], dtype=tf.float32,\n",
    "                                    name='max_cooccurrence_count')\n",
    "            scaling_factor = tf.constant([self.scaling_factor], dtype=tf.float32,\n",
    "                                         name=\"scaling_factor\")\n",
    "\n",
    "            self.__focal_input = tf.placeholder(tf.int32, shape=[self.batch_size],\n",
    "                                                name=\"focal_words\")\n",
    "            self.__context_input = tf.placeholder(tf.int32, shape=[self.batch_size],\n",
    "                                                  name=\"context_words\")\n",
    "            self.__cooccurrence_count = tf.placeholder(tf.float32, shape=[self.batch_size],\n",
    "                                                       name=\"cooccurrence_count\")\n",
    "\n",
    "            focal_embeddings = tf.Variable(\n",
    "                tf.random_uniform([self.vocab_size, self.embedding_size], 1.0, -1.0),\n",
    "                name=\"focal_embeddings\")\n",
    "            context_embeddings = tf.Variable(\n",
    "                tf.random_uniform([self.vocab_size, self.embedding_size], 1.0, -1.0),\n",
    "                name=\"context_embeddings\")\n",
    "\n",
    "            focal_biases = tf.Variable(tf.random_uniform([self.vocab_size], 1.0, -1.0),\n",
    "                                       name='focal_biases')\n",
    "            context_biases = tf.Variable(tf.random_uniform([self.vocab_size], 1.0, -1.0),\n",
    "                                         name=\"context_biases\")\n",
    "\n",
    "            focal_embedding = tf.nn.embedding_lookup([focal_embeddings], self.__focal_input)\n",
    "            context_embedding = tf.nn.embedding_lookup([context_embeddings], self.__context_input)\n",
    "            focal_bias = tf.nn.embedding_lookup([focal_biases], self.__focal_input)\n",
    "            context_bias = tf.nn.embedding_lookup([context_biases], self.__context_input)\n",
    "\n",
    "            weighting_factor = tf.minimum(\n",
    "                1.0,\n",
    "                tf.pow(\n",
    "                    tf.div(self.__cooccurrence_count, count_max),\n",
    "                    scaling_factor))\n",
    "\n",
    "            embedding_product = tf.reduce_sum(tf.multiply(focal_embedding, context_embedding), 1)\n",
    "\n",
    "            log_cooccurrences = tf.log(tf.to_float(self.__cooccurrence_count))\n",
    "\n",
    "            distance_expr = tf.square(tf.add_n([\n",
    "                embedding_product,\n",
    "                focal_bias,\n",
    "                context_bias,\n",
    "                tf.negative(log_cooccurrences)]))\n",
    "\n",
    "            single_losses = tf.multiply(weighting_factor, distance_expr)\n",
    "            self.__total_loss = tf.reduce_sum(single_losses)\n",
    "            tf.summary.scalar(\"GloVe_loss\", self.__total_loss)\n",
    "            self.__optimizer = tf.train.AdagradOptimizer(self.learning_rate).minimize(\n",
    "                self.__total_loss)\n",
    "            self.__summary = tf.summary.merge_all()\n",
    "\n",
    "            self.__combined_embeddings = tf.add(focal_embeddings, context_embeddings,\n",
    "                                                name=\"combined_embeddings\")\n",
    "\n",
    "    def train(self, num_epochs, log_dir=None, summary_batch_interval=1000,\n",
    "              tsne_epoch_interval=None):\n",
    "        should_write_summaries = log_dir is not None and summary_batch_interval\n",
    "        should_generate_tsne = log_dir is not None and tsne_epoch_interval\n",
    "        batches = self.__prepare_batches()\n",
    "        total_steps = 0\n",
    "        with tf.Session(graph=self.__graph) as session:\n",
    "            if should_write_summaries:\n",
    "                print(\"Writing TensorBoard summaries to {}\".format(log_dir))\n",
    "                summary_writer = tf.summary.FileWriter(log_dir, graph=session.graph)\n",
    "            tf.global_variables_initializer().run()\n",
    "            for epoch in range(num_epochs):\n",
    "                shuffle(batches)\n",
    "                for batch_index, batch in enumerate(batches):\n",
    "                    i_s, j_s, counts = batch\n",
    "                    if len(counts) != self.batch_size:\n",
    "                        continue\n",
    "                    feed_dict = {\n",
    "                        self.__focal_input: i_s,\n",
    "                        self.__context_input: j_s,\n",
    "                        self.__cooccurrence_count: counts}\n",
    "                    session.run([self.__optimizer], feed_dict=feed_dict)\n",
    "                    if should_write_summaries and (total_steps + 1) % summary_batch_interval == 0:\n",
    "                        summary_str = session.run(self.__summary, feed_dict=feed_dict)\n",
    "                        summary_writer.add_summary(summary_str, total_steps)\n",
    "                    total_steps += 1\n",
    "                if should_generate_tsne and (epoch + 1) % tsne_epoch_interval == 0:\n",
    "                    current_embeddings = self.__combined_embeddings.eval()\n",
    "                    output_path = os.path.join(log_dir, \"epoch{:03d}.png\".format(epoch + 1))\n",
    "                    self.generate_tsne(output_path, embeddings=current_embeddings)\n",
    "            self.__embeddings = self.__combined_embeddings.eval()\n",
    "            if should_write_summaries:\n",
    "                summary_writer.close()\n",
    "\n",
    "    def embedding_for(self, word_str_or_id):\n",
    "        if isinstance(word_str_or_id, str):\n",
    "            return self.embeddings[self.__word_to_id[word_str_or_id]]\n",
    "        elif isinstance(word_str_or_id, int):\n",
    "            return self.embeddings[word_str_or_id]\n",
    "\n",
    "    def __prepare_batches(self):\n",
    "        if self.__cooccurrence_matrix is None:\n",
    "            raise NotFitToCorpusError(\n",
    "                \"Need to fit model to corpus before preparing training batches.\")\n",
    "        cooccurrences = [(word_ids[0], word_ids[1], count)\n",
    "                         for word_ids, count in self.__cooccurrence_matrix.items()]\n",
    "        i_indices, j_indices, counts = zip(*cooccurrences)\n",
    "        return list(_batchify(self.batch_size, i_indices, j_indices, counts))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.__words)\n",
    "\n",
    "    @property\n",
    "    def words(self):\n",
    "        if self.__words is None:\n",
    "            raise NotFitToCorpusError(\"Need to fit model to corpus before accessing words.\")\n",
    "        return self.__words\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        if self.__embeddings is None:\n",
    "            raise NotTrainedError(\"Need to train model before accessing embeddings\")\n",
    "        return self.__embeddings\n",
    "\n",
    "    def id_for_word(self, word):\n",
    "        if self.__word_to_id is None:\n",
    "            raise NotFitToCorpusError(\"Need to fit model to corpus before looking up word ids.\")\n",
    "        return self.__word_to_id[word]\n",
    "\n",
    "    def generate_tsne(self, path=None, size=(100, 100), word_count=1000, embeddings=None):\n",
    "        if embeddings is None:\n",
    "            embeddings = self.embeddings\n",
    "        from sklearn.manifold import TSNE\n",
    "        tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "        low_dim_embs = tsne.fit_transform(embeddings[:word_count, :])\n",
    "        labels = self.words[:word_count]\n",
    "        return _plot_with_labels(low_dim_embs, labels, path, size)\n",
    "\n",
    "\n",
    "def _context_windows(region, left_size, right_size):\n",
    "    for i, word in enumerate(region):\n",
    "        start_index = i - left_size\n",
    "        end_index = i + right_size\n",
    "        left_context = _window(region, start_index, i - 1)\n",
    "        right_context = _window(region, i + 1, end_index)\n",
    "        yield (left_context, word, right_context)\n",
    "\n",
    "\n",
    "def _window(region, start_index, end_index):\n",
    "    \"\"\"\n",
    "    Returns the list of words starting from `start_index`, going to `end_index`\n",
    "    taken from region. If `start_index` is a negative number, or if `end_index`\n",
    "    is greater than the index of the last word in region, this function will pad\n",
    "    its return value with `NULL_WORD`.\n",
    "    \"\"\"\n",
    "    last_index = len(region) + 1\n",
    "    selected_tokens = region[max(start_index, 0):min(end_index, last_index) + 1]\n",
    "    return selected_tokens\n",
    "\n",
    "\n",
    "def _device_for_node(n):\n",
    "    if n.type == \"MatMul\":\n",
    "        return \"/gpu:0\"\n",
    "    else:\n",
    "        return \"/cpu:0\"\n",
    "\n",
    "\n",
    "def _batchify(batch_size, *sequences):\n",
    "    for i in range(0, len(sequences[0]), batch_size):\n",
    "        yield tuple(sequence[i:i+batch_size] for sequence in sequences)\n",
    "\n",
    "\n",
    "def _plot_with_labels(low_dim_embs, labels, path, size):\n",
    "    import matplotlib.pyplot as plt\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    figure = plt.figure(figsize=size)  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right',\n",
    "                     va='bottom')\n",
    "    if path is not None:\n",
    "        figure.savefig(path)\n",
    "        plt.close(figure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class NotTrainedError(Exception):\n",
    "    pass\n",
    "\n",
    "class NotFitToCorpusError(Exception):\n",
    "    pass\n",
    "\n",
    "class GloVeModel():\n",
    "    def __init__(self, embedding_size, context_size, max_vocab_size=100000, min_occurrences=1,\n",
    "                 scaling_factor=3/4, cooccurrence_cap=100, batch_size=512, learning_rate=0.05,\n",
    "                load_context_vecs = None, load_focal_vecs = None):\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        if isinstance(context_size, tuple):\n",
    "            self.left_context, self.right_context = context_size\n",
    "        elif isinstance(context_size, int):\n",
    "            self.left_context = self.right_context = context_size\n",
    "        else:\n",
    "            raise ValueError(\"`context_size` should be an int or a tuple of two ints\")\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.min_occurrences = min_occurrences\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.cooccurrence_cap = cooccurrence_cap\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.__words = None\n",
    "        self.__word_to_id = None\n",
    "        self.__cmatrix = None\n",
    "        self.__num_pairs = None\n",
    "        \n",
    "        \n",
    "        self.__embeddings = None\n",
    "        self.__focal_embeddings = None\n",
    "        self.__context_embeddings = None\n",
    "        self.__focal = None\n",
    "        self.__context= None\n",
    "        \n",
    "        self.__load_context_vecs = load_context_vecs\n",
    "        self.__load_focal_vecs = load_focal_vecs\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit_to_cmatrix(self, cmatrix, wordCountFile):\n",
    "        \"\"\"\n",
    "        Fits a pre-build Cooccurence matrix to the model\n",
    "        \"\"\"\n",
    "        print(\"In here\")\n",
    "        wordCount = pickle.load(open(wordCountFile,'rb'))\n",
    "        vocab = wordCount.most_common(self.max_vocab_size)\n",
    "\n",
    "        ## Creating the Word-ID dictionaries\n",
    "        self.__id_to_word = {i:x[0] for i,x in enumerate(vocab)}\n",
    "\n",
    "        self.__word_to_id = {value:key for key,value in self.__id_to_word.items()}\n",
    "        \n",
    "        self.__words = set(self.__word_to_id.keys())\n",
    "        \n",
    "        self.__cmatrix = cmatrix.tocoo()\n",
    "        \n",
    "        self.__num_pairs = len(self.__cmatrix.row)\n",
    "        \n",
    "        self.__build_graph()\n",
    "        \n",
    "           \n",
    "\n",
    "    def __build_graph(self):\n",
    "        self.__graph = tf.Graph()\n",
    "        with self.__graph.as_default(), self.__graph.device(\"/device:GPU:0\"):\n",
    "            count_max = tf.constant([self.cooccurrence_cap], dtype=tf.float32,\n",
    "                                    name='max_cooccurrence_count')\n",
    "            scaling_factor = tf.constant([self.scaling_factor], dtype=tf.float32,\n",
    "                                         name=\"scaling_factor\")\n",
    "\n",
    "            self.__focal_input = tf.placeholder(tf.int32, shape=[self.batch_size],\n",
    "                                                name=\"focal_words\")\n",
    "            self.__context_input = tf.placeholder(tf.int32, shape=[self.batch_size],\n",
    "                                                  name=\"context_words\")\n",
    "            self.__cooccurrence_count = tf.placeholder(tf.float32, shape=[self.batch_size],\n",
    "                                                       name=\"cooccurrence_count\")\n",
    "            \n",
    "            print(\"Right here\")\n",
    "            if self.__load_focal_vecs is None:\n",
    "                focal_embeddings = tf.Variable(\n",
    "                    tf.random_uniform([self.vocab_size, self.embedding_size], 1.0, -1.0),\n",
    "                    name=\"focal_embeddings\")\n",
    "            else:\n",
    "                print(\"Loading pretrained values\")\n",
    "                focal_embeddings = tf.Variable(self.__load_focal_vecs,name=\"focal_embeddings\")\n",
    "            \n",
    "            if self.__load_context_vecs is None:\n",
    "                context_embeddings = tf.Variable(\n",
    "                    tf.random_uniform([self.vocab_size, self.embedding_size], 1.0, -1.0),\n",
    "                    name=\"context_embeddings\")\n",
    "            else:\n",
    "                print(\"Loading pretrained values\")\n",
    "                context_embeddings = tf.Variable(self.__load_context_vecs,name=\"context_embeddings\")\n",
    "                \n",
    "\n",
    "            focal_biases = tf.Variable(tf.random_uniform([self.vocab_size], 1.0, -1.0),\n",
    "                                       name='focal_biases')\n",
    "            context_biases = tf.Variable(tf.random_uniform([self.vocab_size], 1.0, -1.0),\n",
    "                                         name=\"context_biases\")\n",
    "\n",
    "            focal_embedding = tf.nn.embedding_lookup([focal_embeddings], self.__focal_input)\n",
    "            context_embedding = tf.nn.embedding_lookup([context_embeddings], self.__context_input)\n",
    "            focal_bias = tf.nn.embedding_lookup([focal_biases], self.__focal_input)\n",
    "            context_bias = tf.nn.embedding_lookup([context_biases], self.__context_input)\n",
    "\n",
    "            weighting_factor = tf.minimum(\n",
    "                1.0,\n",
    "                tf.pow(\n",
    "                    tf.div(self.__cooccurrence_count, count_max),\n",
    "                    scaling_factor))\n",
    "\n",
    "            embedding_product = tf.reduce_sum(tf.multiply(focal_embedding, context_embedding), 1)\n",
    "\n",
    "            log_cooccurrences = tf.log(tf.to_float(self.__cooccurrence_count))\n",
    "\n",
    "            distance_expr = tf.square(tf.add_n([\n",
    "                embedding_product,\n",
    "                focal_bias,\n",
    "                context_bias,\n",
    "                tf.negative(log_cooccurrences)]))\n",
    "\n",
    "            single_losses = tf.multiply(weighting_factor, distance_expr)\n",
    "            self.__total_loss = tf.reduce_sum(single_losses)\n",
    "            tf.summary.scalar(\"GloVe_loss\", self.__total_loss)\n",
    "            self.__optimizer = tf.train.AdagradOptimizer(self.learning_rate).minimize(\n",
    "                self.__total_loss)\n",
    "            self.__summary = tf.summary.merge_all()\n",
    "\n",
    "            self.__combined_embeddings = tf.add(focal_embeddings, context_embeddings,\n",
    "                                                name=\"combined_embeddings\")\n",
    "            \n",
    "            self.__focal_embeddings = focal_embeddings\n",
    "            self.__context_embeddings = context_embeddings\n",
    "\n",
    "    def train(self, num_steps = 1000, log_dir=None, summary_batch_interval=1000,\n",
    "              tsne_epoch_interval=None):\n",
    "       \n",
    "        \n",
    "        batches = self.getBatch()\n",
    "        total_steps = 0\n",
    "        \n",
    "        with tf.Session(graph=self.__graph, config = tf.ConfigProto(allow_soft_placement = True)) as session:\n",
    "            \n",
    "            tf.global_variables_initializer().run()\n",
    "            \n",
    "            for step in range(num_steps):\n",
    "                batch = self.getBatch()\n",
    "                \n",
    "                i_s, j_s, counts = zip(*batch)\n",
    "                \n",
    "                feed_dict = {\n",
    "                        self.__focal_input: i_s,\n",
    "                        self.__context_input: j_s,\n",
    "                        self.__cooccurrence_count: counts}\n",
    "                \n",
    "                session.run([self.__optimizer], feed_dict=feed_dict)\n",
    "            \n",
    "            \n",
    "                    \n",
    "                total_steps += 1\n",
    "                \n",
    "            self.__embeddings = self.__combined_embeddings.eval()\n",
    "            self.__focal  = self.__focal_embeddings.eval()\n",
    "            self.__context = self.__context_embeddings.eval()\n",
    "          \n",
    "            \n",
    "            \n",
    "    def getBatch(self):\n",
    "        \n",
    "        batch = []\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ind = np.random.randint(self.__num_pairs)\n",
    "            \n",
    "            #Shuffling the center and context words because we have stored values only in one direction\n",
    "            \n",
    "            if np.random.random()>0.5:\n",
    "                batch.append( (self.__cmatrix.row[ind], self.__cmatrix.col[ind], self.__cmatrix.data[ind]) )\n",
    "            else:\n",
    "                batch.append( (self.__cmatrix.col[ind], self.__cmatrix.row[ind], self.__cmatrix.data[ind]) )\n",
    "            \n",
    "            \n",
    "        return batch\n",
    "    \n",
    "    def saveEmbeddings(self,suffix =''):\n",
    "        \n",
    "        \n",
    "        \n",
    "        pickle.dump(self.__focal, open('focal_embed'+suffix,'wb'))\n",
    "        pickle.dump(self.__context, open('context_embed'+suffix,'wb'))\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def embedding_for(self, word_str_or_id):\n",
    "        if isinstance(word_str_or_id, str):\n",
    "            return self.embeddings[self.__word_to_id[word_str_or_id]]\n",
    "        elif isinstance(word_str_or_id, int):\n",
    "            return self.embeddings[word_str_or_id]\n",
    "\n",
    "    def __prepare_batches(self):\n",
    "        if self.__cmatrix is None:\n",
    "            raise NotFitToCorpusError(\n",
    "                \"Need to fit model to corpus before preparing training batches.\")\n",
    "        cooccurrences = [(word_ids[0], word_ids[1], count)\n",
    "                         for word_ids, count in self.__cmatrix.items()]\n",
    "        i_indices, j_indices, counts = zip(*cooccurrences)\n",
    "        return list(_batchify(self.batch_size, i_indices, j_indices, counts))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.__words)\n",
    "\n",
    "    @property\n",
    "    def words(self):\n",
    "        if self.__words is None:\n",
    "            raise NotFitToCorpusError(\"Need to fit model to corpus before accessing words.\")\n",
    "        return self.__words\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        if self.__embeddings is None:\n",
    "            raise NotTrainedError(\"Need to train model before accessing embeddings\")\n",
    "        return self.__embeddings\n",
    "\n",
    "    def id_for_word(self, word):\n",
    "        if self.__word_to_id is None:\n",
    "            raise NotFitToCorpusError(\"Need to fit model to corpus before looking up word ids.\")\n",
    "        return self.__word_to_id[word]\n",
    "\n",
    "    def generate_tsne(self, path=None, size=(100, 100), word_count=1000, embeddings=None):\n",
    "        if embeddings is None:\n",
    "            embeddings = self.embeddings\n",
    "        from sklearn.manifold import TSNE\n",
    "        tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "        low_dim_embs = tsne.fit_transform(embeddings[:word_count, :])\n",
    "        labels = self.words[:word_count]\n",
    "        return _plot_with_labels(low_dim_embs, labels, path, size)\n",
    "\n",
    "\n",
    "def _context_windows(region, left_size, right_size):\n",
    "    for i, word in enumerate(region):\n",
    "        start_index = i - left_size\n",
    "        end_index = i + right_size\n",
    "        left_context = _window(region, start_index, i - 1)\n",
    "        right_context = _window(region, i + 1, end_index)\n",
    "        yield (left_context, word, right_context)\n",
    "\n",
    "\n",
    "def _window(region, start_index, end_index):\n",
    "    \"\"\"\n",
    "    Returns the list of words starting from `start_index`, going to `end_index`\n",
    "    taken from region. If `start_index` is a negative number, or if `end_index`\n",
    "    is greater than the index of the last word in region, this function will pad\n",
    "    its return value with `NULL_WORD`.\n",
    "    \"\"\"\n",
    "    last_index = len(region) + 1\n",
    "    selected_tokens = region[max(start_index, 0):min(end_index, last_index) + 1]\n",
    "    return selected_tokens\n",
    "\n",
    "\n",
    "def _device_for_node(n):\n",
    "    if n.type == \"MatMul\":\n",
    "        return \"/gpu:0\"\n",
    "    else:\n",
    "        return \"/cpu:0\"\n",
    "\n",
    "\n",
    "def _batchify(batch_size, *sequences):\n",
    "    for i in range(0, len(sequences[0]), batch_size):\n",
    "        yield tuple(sequence[i:i+batch_size] for sequence in sequences)\n",
    "\n",
    "\n",
    "def _plot_with_labels(low_dim_embs, labels, path, size):\n",
    "    import matplotlib.pyplot as plt\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    figure = plt.figure(figsize=size)  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right',\n",
    "                     va='bottom')\n",
    "    if path is not None:\n",
    "        figure.savefig(path)\n",
    "        plt.close(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585257661966555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000000x1000000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 124274397 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.load(open('cooccurMat_0','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    b = pickle.load(open('cooccurMat_'+str(i),'rb'))\n",
    "    a = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000000x1000000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 474850148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GloVeModel(embedding_size=100, context_size=10,max_vocab_size=1000000,load_context_vecs=context_array, load_focal_vecs= focal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In here\n",
      "Right here\n",
      "Loading pretrained values\n",
      "Loading pretrained values\n"
     ]
    }
   ],
   "source": [
    "model.fit_to_cmatrix(a, 'wordCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "e= pickle.load(open('wordCount','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_array = pickle.load(open('context_embed_10','rb'))\n",
    "focal_array = pickle.load(open('focal_embed_10','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_array_new = pickle.load(open('context_embed','rb'))\n",
    "focal_array_new = pickle.load(open('focal_embed','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42820725,  0.3279405 ,  0.00255706,  0.13728783, -0.15837634,\n",
       "       -0.2224654 ,  0.02430093,  0.2706435 ,  0.16189925, -0.3963217 ,\n",
       "        0.02753036, -0.33744398,  0.01478683,  0.04167126, -0.01372743,\n",
       "       -0.36690328,  0.18163441, -0.14389753,  0.08244283,  0.03969737,\n",
       "       -0.12260118, -0.03833848,  0.41795307,  0.31592208,  0.43021423,\n",
       "       -0.0462651 , -0.19884585, -0.2516142 , -0.25694767,  0.13515314,\n",
       "       -0.2147453 ,  0.42421624,  0.11931733, -0.00648857,  0.03249184,\n",
       "       -0.44927317, -0.37367916,  0.06678842, -0.19567408,  0.00882525,\n",
       "       -0.19148587, -0.36658376,  0.1280104 , -0.16169503, -0.07901064,\n",
       "       -0.1509476 , -0.08124208, -0.0606637 ,  0.07976799, -0.06875487,\n",
       "       -0.304153  ,  0.24482484,  0.02833407,  0.29307896,  0.20560703,\n",
       "        0.04874455, -0.15811616,  0.27799016, -0.17931765, -0.1190341 ,\n",
       "        0.01104508, -0.01776258, -0.25723696, -0.48068726,  0.19116622,\n",
       "       -0.55141085, -0.08873697,  0.11446474, -0.20272389, -0.11596572,\n",
       "       -0.20532297,  0.09206215,  0.07961705,  0.10416465, -0.10851215,\n",
       "        0.21066792,  0.20967358,  0.37610528, -0.18326773, -0.07023628,\n",
       "        0.39362794,  0.17059419,  0.14519261,  0.4858826 ,  0.3329139 ,\n",
       "        0.15381901, -0.37993383, -0.07932267,  0.11117616, -0.33160946,\n",
       "        0.1742192 ,  0.09206223, -0.03920136, -0.0916329 ,  0.01548082,\n",
       "        0.06720525,  0.40997547,  0.04642709,  0.13990173, -0.31342033],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_array_new[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42820725,  0.3279405 ,  0.00255706,  0.13728783, -0.15837634,\n",
       "       -0.2224654 ,  0.02430093,  0.2706435 ,  0.16189925, -0.3963217 ,\n",
       "        0.02753036, -0.33744398,  0.01478683,  0.04167126, -0.01372743,\n",
       "       -0.36690328,  0.18163441, -0.14389753,  0.08244283,  0.03969737,\n",
       "       -0.12260118, -0.03833848,  0.41795307,  0.31592208,  0.43021423,\n",
       "       -0.0462651 , -0.19884585, -0.2516142 , -0.25694767,  0.13515314,\n",
       "       -0.2147453 ,  0.42421624,  0.11931733, -0.00648857,  0.03249184,\n",
       "       -0.44927317, -0.37367916,  0.06678842, -0.19567408,  0.00882525,\n",
       "       -0.19148587, -0.36658376,  0.1280104 , -0.16169503, -0.07901064,\n",
       "       -0.1509476 , -0.08124208, -0.0606637 ,  0.07976799, -0.06875487,\n",
       "       -0.304153  ,  0.24482484,  0.02833407,  0.29307896,  0.20560703,\n",
       "        0.04874455, -0.15811616,  0.27799016, -0.17931765, -0.1190341 ,\n",
       "        0.01104508, -0.01776258, -0.25723696, -0.48068726,  0.19116622,\n",
       "       -0.55141085, -0.08873697,  0.11446474, -0.20272389, -0.11596572,\n",
       "       -0.20532297,  0.09206215,  0.07961705,  0.10416465, -0.10851215,\n",
       "        0.21066792,  0.20967358,  0.37610528, -0.18326773, -0.07023628,\n",
       "        0.39362794,  0.17059419,  0.14519261,  0.4858826 ,  0.3329139 ,\n",
       "        0.15381901, -0.37993383, -0.07932267,  0.11117616, -0.33160946,\n",
       "        0.1742192 ,  0.09206223, -0.03920136, -0.0916329 ,  0.01548082,\n",
       "        0.06720525,  0.40997547,  0.04642709,  0.13990173, -0.31342033],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_array[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
